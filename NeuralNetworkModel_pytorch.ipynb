{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "j9Rf81DfqYJY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bZRSYuqOqU96",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "77-ebj0grnNf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Downloading Datasets"
      ]
    },
    {
      "metadata": {
        "id": "KNKX6Cf9qp_z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset=dsets.MNIST(root='.',train=True,transform=transforms.ToTensor(),download=True)\n",
        "test_dataset=dsets.MNIST(root='.',train=False,transform=transforms.ToTensor(),download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "905ZKdOIsKnE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Defining hyperparameters\n"
      ]
    },
    {
      "metadata": {
        "id": "SG5H1WHVsJq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size=100\n",
        "num_iters=3000\n",
        "epochs=int(num_iters*batch_size/len(train_dataset))\n",
        "input_dim=28*28\n",
        "hidden_dim=100\n",
        "output_dim=10\n",
        "learning_rate=0.1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8zmdfD6srqQl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Making datasets iterable "
      ]
    },
    {
      "metadata": {
        "id": "m9xPyu2PrDYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A-eR-Ixgsr5J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Creating model class"
      ]
    },
    {
      "metadata": {
        "id": "KKvJPdj6sIDX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FeedforwardNeuralNetwork(nn.Module):\n",
        "  \n",
        "  def __init__(self,input_dim,hidden_dim,output_dim):\n",
        "    \n",
        "    super(FeedforwardNeuralNetwork,self).__init__ ()\n",
        "    \n",
        "    #first linear layer\n",
        "    self.linear1=nn.Linear(input_dim,hidden_dim)\n",
        "    \n",
        "    #non-linearity\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "    \n",
        "    #second linear layer\n",
        "    self.linear2=nn.Linear(hidden_dim,output_dim)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    \n",
        "    out=self.linear1(x)\n",
        "    \n",
        "    out=self.sigmoid(out)\n",
        "    \n",
        "    out=self.linear2(out)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lfa51LKIxdKR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Instantiating Model Class"
      ]
    },
    {
      "metadata": {
        "id": "uAumA0Byu7Tt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=FeedforwardNeuralNetwork(input_dim,hidden_dim,output_dim)\n",
        "\n",
        "#selecting cross entropy loss function\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "#selecting optimizer - Stochastic gradient descent \n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JJ2cxD6OylTn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Training the model"
      ]
    },
    {
      "metadata": {
        "id": "C4gUldcyytEx",
        "colab_type": "code",
        "outputId": "1d773de2-efce-427f-bb8f-fec983c6a934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "iters=0\n",
        "\n",
        "for num_epochs in range(epochs):\n",
        "  for i, (images,labels) in enumerate(train_loader):\n",
        "    \n",
        "    images=Variable(images.view(-1,784))  #to calculate gradients\n",
        "    \n",
        "    labels=Variable(labels)               #to calculate gradients\n",
        "    \n",
        "    outputs=model(images)                 #calculating output\n",
        "    \n",
        "    optimizer.zero_grad()                 #clearing gradient buffers\n",
        "    \n",
        "    loss=criterion(outputs,labels)        #calculating loss \n",
        "    \n",
        "    loss.backward()                       #calculating gradients\n",
        "    \n",
        "    optimizer.step()                      #updating parameters\n",
        "    \n",
        "    iters+=1\n",
        "    \n",
        "    if iters%500==0:                      #to calculate accuracy\n",
        "      \n",
        "      correct=0\n",
        "      \n",
        "      total=0\n",
        "      \n",
        "      for images,labels in test_loader:\n",
        "        images=Variable(images.view(-1,784))\n",
        "        \n",
        "        outputs=model(images)\n",
        "        \n",
        "        _, predicted= torch.max(outputs.data,1)\n",
        "        \n",
        "        correct += (predicted==labels).sum().item()\n",
        "        \n",
        "        total+=labels.size(0)\n",
        "        \n",
        "      print('Iteration:{}  Loss:{}   Accuracy:{}'.format(iters, loss , 100*correct/total))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:500  Loss:0.5005639791488647   Accuracy:86.43\n",
            "Iteration:1000  Loss:0.5518031716346741   Accuracy:89.63\n",
            "Iteration:1500  Loss:0.4898417592048645   Accuracy:90.57\n",
            "Iteration:2000  Loss:0.20130138099193573   Accuracy:91.22\n",
            "Iteration:2500  Loss:0.27877938747406006   Accuracy:91.75\n",
            "Iteration:3000  Loss:0.21195927262306213   Accuracy:92.15\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}